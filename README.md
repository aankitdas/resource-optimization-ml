# ðŸš€ Resource Optimization ML Pipeline

An end-to-end machine learning solution for optimizing service placement across AWS regions, reducing latency and costs while maintaining reliability.

**Live Dashboard:** [View on Hugging Face Spaces](https://huggingface.co/spaces/YOUR_USERNAME/resource-optimization-ml)

## ðŸ“Š Project Overview

This project demonstrates a complete ML pipeline inspired by Amazon's Region Flexibility Engineering team challenges:

- **Problem:** Optimize service placement across 5 AWS regions to reduce latency and costs
- **Solution:** ML-driven placement strategy with A/B testing validation
- **Results:** 5.25% latency reduction, 4.92% cost savings, statistically significant (p < 0.001)

## ðŸŽ¯ Key Results

| Metric | Result |
|--------|--------|
| Latency Reduction | **5.25%** âœ… |
| Cost Savings | **4.92%** âœ… |
| Critical Service Improvement | **9.30%** âœ… |
| Statistical Significance | **p < 0.001** âœ… |
| Placement Efficiency | **378 vs 452 pairs** (-16%) |

## ðŸ› ï¸ Architecture

### Data Pipeline
- **150+ services** with metadata (memory, CPU, latency sensitivity)
- **1.6M+ traffic records** across 5 AWS regions
- **30K+ placement records** with latency and error rates
- **Regional latency matrix** for cross-region communication costs

### ML Models

#### Model 1: Latency Prediction (XGBoost Regression)
- Predicts service latency for a given placement
- **Features:** Memory, CPU cores, traffic patterns, outbound latency, service dependencies
- **Performance:** RMSE = 28.7ms, MAE = 24.67ms
- **Top Features:** Request variability, outbound latency, average traffic

#### Model 2: Placement Strategy (Random Forest Classifier)
- Classifies services for optimal regional distribution
- **Features:** Traffic volume, dependencies, latency sensitivity, resource requirements
- **Performance:** 100% accuracy on test set

### A/B Testing Framework
- **Control:** Random service placement (baseline)
- **Treatment:** ML-optimized placement using model predictions
- **Statistical Test:** Independent t-test (t=7.02, p<0.001)
- **Result:** Statistically significant improvement âœ…

## ðŸ“ Project Structure

```
resource-optimization-ml/
â”œâ”€â”€ data/                           # Generated datasets
â”‚   â”œâ”€â”€ services.csv               # Service metadata
â”‚   â”œâ”€â”€ regional_latency.csv       # Cross-region latency
â”‚   â”œâ”€â”€ traffic_patterns.csv       # Hourly traffic by service/region
â”‚   â””â”€â”€ service_placement.csv      # Historical placements
â”‚
â”œâ”€â”€ models/                         # Trained ML models
â”‚   â”œâ”€â”€ xgboost_latency_model.pkl  # Latency prediction model
â”‚   â”œâ”€â”€ random_forest_placement_model.pkl  # Placement strategy model
â”‚   â”œâ”€â”€ scaler_latency.pkl         # Feature scaler
â”‚   â”œâ”€â”€ scaler_classification.pkl  # Feature scaler
â”‚   â””â”€â”€ feature_importance_*.csv   # Feature importance analysis
â”‚
â”œâ”€â”€ results/                        # A/B test results
â”‚   â”œâ”€â”€ ab_test_results.json       # Statistical comparison
â”‚   â”œâ”€â”€ control_placement.csv      # Control group placements
â”‚   â””â”€â”€ treatment_placement.csv    # Treatment group placements
â”‚
â”œâ”€â”€ notebooks/                      # Analysis notebooks (optional)
â”‚
â”œâ”€â”€ data_generation.py              # Generate synthetic dataset
â”œâ”€â”€ setup_database.py               # Load data into SQLite
â”œâ”€â”€ explore_data.py                 # Data exploration and SQL queries
â”œâ”€â”€ train_models.py                 # Train ML models
â”œâ”€â”€ ab_test_simulation.py           # Run A/B test simulation
â”œâ”€â”€ app.py                          # Streamlit dashboard
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # This file
â””â”€â”€ .gitignore
```

## ðŸš€ Quick Start

### Local Development

1. **Clone the repository**
```bash
git clone https://github.com/YOUR_USERNAME/resource-optimization-ml.git
cd resource-optimization-ml
```

2. **Install dependencies** (using uv or pip)
```bash
uv pip install -r requirements.txt
```

3. **Generate data**
```bash
uv run python data_generation.py
```

4. **Setup database**
```bash
uv run python setup_database.py
```

5. **Explore data**
```bash
uv run python explore_data.py
```

6. **Train models**
```bash
uv run python train_models.py
```

7. **Run A/B test simulation**
```bash
uv run python ab_test_simulation.py
```

8. **Launch dashboard**
```bash
uv run streamlit run app.py
```

The dashboard will open at `http://localhost:8501`

## ðŸ“Š Dashboard Features

### ðŸ“ˆ Overview
- Service distribution by memory, CPU, and latency sensitivity
- Traffic volume analysis across regions
- Total statistics (150 services, 5 regions, 1.6M records)

### ðŸŽ¯ A/B Test Results
- Side-by-side comparison of control vs treatment strategies
- Latency reduction: 5.25%
- Cost savings: 4.92%
- Statistical significance test results (p-value, t-statistic)

### ðŸ—ºï¸ Regional Analysis
- Interactive latency heatmap between all region pairs
- Regional statistics (min, max, std deviation)
- Identify high-latency corridors

### ðŸ”§ Service Details
- Interactive service explorer
- Per-service placement across regions
- Instance count and latency metrics

## ðŸ§  Technical Stack

| Component | Tool | Purpose |
|-----------|------|---------|
| Data Storage | SQLite | Lightweight database for local development |
| Data Processing | Pandas, NumPy | Data manipulation and feature engineering |
| ML Framework | scikit-learn, XGBoost | Model training and prediction |
| Statistics | SciPy | A/B testing and significance tests |
| Visualization | Plotly, Streamlit | Interactive dashboards |
| Deployment | Hugging Face Spaces | Live dashboard hosting |

## ðŸ“ˆ Model Performance

### XGBoost (Latency Prediction)
```
RMSE: 28.7007 ms
MAE:  24.6690 ms
RÂ²:   -0.0674 (indicates high variance in data)
```

**Top 5 Important Features:**
1. Request Variability (CV): 21.7%
2. Outbound Latency: 17.6%
3. Average Requests: 14.2%
4. Dependencies: 13.5%
5. Number of Instances: 11.7%

### Random Forest (Placement Strategy)
```
Accuracy: 100%
Precision: 1.00
Recall: 1.00
F1-Score: 1.00
```

**Top Features:**
1. Traffic Volume: 54.5%
2. Dependencies: 13.8%
3. Latency Sensitivity: 13.7%

## ðŸ§ª A/B Test Methodology

**Hypothesis:** ML-optimized placement reduces latency compared to random placement

**Sample Size:** 150 services Ã— 5 regions = 750 potential placements

**Metrics:**
- Primary: Average latency (ms)
- Secondary: Total cost ($), redundancy score, critical service latency
- Efficiency: Number of placement pairs (fewer = more efficient)

**Test Type:** Independent samples t-test
- Null hypothesis (Hâ‚€): Î¼_control = Î¼_treatment
- Alternative hypothesis (Hâ‚): Î¼_control â‰  Î¼_treatment
- Significance level: Î± = 0.05

**Result:** Reject Hâ‚€ (p < 0.001)
- The ML-optimized placement significantly reduces latency

## ðŸ’¡ Key Insights

1. **Latency-critical services benefit most** from optimized placement (9.3% improvement vs 5.25% average)
2. **Traffic patterns drive decisions** - high-traffic services benefit from multi-region placement
3. **Regional cost differences matter** - avoiding expensive regions saves 4.92% without sacrificing latency
4. **Placement efficiency improves** - ML uses 16% fewer placement pairs while reducing latency
5. **Statistical rigor matters** - The improvement is not due to chance (p < 0.001)

## ðŸš€ Future Enhancements

### Short-term
- [ ] Add notebook with exploratory data analysis
- [ ] Include feature importance visualizations
- [ ] Create prediction API endpoint

### Medium-term
- [ ] Integrate real AWS CloudWatch metrics
- [ ] Add model retraining pipeline
- [ ] Implement automated alerting
- [ ] Support multi-cloud scenarios (GCP, Azure)

### Long-term
- [ ] Deploy as microservice recommendation engine
- [ ] Build feedback loop for model improvement
- [ ] Create cost optimization module
- [ ] Add capacity planning features

## ðŸ“š Learning Resources

This project demonstrates:
- âœ… SQL data querying and aggregation
- âœ… Python data manipulation (Pandas, NumPy)
- âœ… Machine learning model training (scikit-learn, XGBoost)
- âœ… Feature engineering and preprocessing
- âœ… Statistical hypothesis testing
- âœ… A/B testing methodology
- âœ… Data visualization (Plotly, Streamlit)
- âœ… Full-stack ML deployment

## ðŸ“ License

This project is open source and available under the MIT License.

## ðŸ‘¤ Author

Built as a portfolio project demonstrating ML engineering capabilities for cloud infrastructure optimization.

---

**Questions or feedback?** Open an issue or reach out!

**Live Dashboard:** [Hugging Face Spaces](https://huggingface.co/spaces/aankitdas/resource-optimization-ml)
**GitHub:** [resource-optimization-ml](https://github.com/aankitdas/resource-optimization-ml)